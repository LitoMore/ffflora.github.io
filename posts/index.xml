<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Flora&#39;s</title>
    <link>https://ffflora.github.io/posts/</link>
    <description>Recent content in Posts on Flora&#39;s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2020 10:25:43 -0800</lastBuildDate>
    
	<atom:link href="https://ffflora.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Notes on the paper(NLP): Efficient Estimation of Word Representations in Vector Space</title>
      <link>https://ffflora.github.io/posts/efficient-estimation/</link>
      <pubDate>Fri, 28 Feb 2020 10:25:43 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/efficient-estimation/</guid>
      <description>Background Knowledge Machine Learning
Calculus
Programming Skills: C++, PyTorch
Language Model: sentence = {x1,x2,....,xn}
use frequency of the corpus instead of the probabilities:
p(xi) = count(xi)/N
p(xi-1,xi) = count(xi-1,xi)/N
Use conditional probability p(xi|xi-1):
p(xi|xi-1) = count(xi-1,xi)/count(xi)
Markov chain k-gram model
Sigmod Gradient Descent Softmax Distributed Representation The origin of NLP deep learning: features.
One-hot representation Easy to represent, but the problems are
 More words, higher the dimension. There are no connections between the words.</description>
    </item>
    
    <item>
      <title>React(1): Basics of React</title>
      <link>https://ffflora.github.io/posts/react-note1/</link>
      <pubDate>Tue, 28 Jan 2020 00:50:02 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/react-note1/</guid>
      <description>Basics of React (Most of the materials come from React Official Document) JSX Represents Objects Babel compiles JSX down to React.createElement() calls.
These two examples are identical:
const element = ( &amp;lt;h1 className=&amp;#34;greeting&amp;#34;&amp;gt; Hello, world! &amp;lt;/h1&amp;gt; ); const element = React.createElement( &amp;#39;h1&amp;#39;, {className: &amp;#39;greeting&amp;#39;}, &amp;#39;Hello, world!&amp;#39; ); React.createElement() performs a few checks to help you write bug-free code but essentially it creates an object like this:
// Note: this structure is simplified const element = { type: &amp;#39;h1&amp;#39;, props: { className: &amp;#39;greeting&amp;#39;, children: &amp;#39;Hello, world!</description>
    </item>
    
    <item>
      <title>Node.js Error Message Resolved</title>
      <link>https://ffflora.github.io/posts/node-error/</link>
      <pubDate>Fri, 24 Jan 2020 15:49:23 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/node-error/</guid>
      <description>So I had encountered these Error Messages when running a project:
npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! grpc@1.10.1 install: `node-pre-gyp install --fallback-to-build --library=static_library` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the grpc@1.10.1 install script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR!</description>
    </item>
    
    <item>
      <title>Conda Install Error Message Resolved</title>
      <link>https://ffflora.github.io/posts/conda-removeerror/</link>
      <pubDate>Thu, 16 Jan 2020 22:42:06 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/conda-removeerror/</guid>
      <description>I encountered with the error message today when I use conda install xxx :
RemoveError: &amp;#39;xxxxxx&amp;#39; is a dependency of conda and cannot be removed from conda&amp;#39;s operating environment. Solved by :
conda clean -all conda update --all</description>
    </item>
    
    <item>
      <title>Business Analyst ABCs and Interview Preparation</title>
      <link>https://ffflora.github.io/posts/ba/</link>
      <pubDate>Thu, 09 Jan 2020 22:02:18 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/ba/</guid>
      <description>Data is increasingly being considered an important asset within organization.
BA Oversee every process in typical E-commerce to look out for potential issues, problems and potential for optimization to boost the business performance.
 Under CFO or COO
 BI team
 Support various department:
  warehouse, UX design, marketing, operation, international
DA  Under CTO DA/DS team Support marketing/strategy/BI and work with technology closely.  Important Metrics and KPIs  Traffic: - Website  Conversion Rate</description>
    </item>
    
    <item>
      <title>MongoDB Useful Commands</title>
      <link>https://ffflora.github.io/posts/mongodb/</link>
      <pubDate>Thu, 09 Jan 2020 21:52:20 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/mongodb/</guid>
      <description>SQL vs MongoDB    SQL MongoDB     Table Collection   Row Document   Col Field   Primary Key ObjectId   Index Index   Embedded Table Embedded Table   Array Array    Common command lines
use dtbase #use some specific database db.collection.updateOne({tags:&amp;#39;abc&amp;#39;},{$set:{name:&amp;#39;flora&amp;#39;}}) db.collection.updatemMany({tags:&amp;#39;abc&amp;#39;},{$set:{name:&amp;#39;flora&amp;#39;}}) db.collection.insertOne({&amp;#39;name&amp;#39;:&amp;#39;Flora&amp;#39;,&amp;#39;age&amp;#39;:&amp;#39;17&amp;#39;}) db.getCollection(&amp;#39;collection_name&amp;#39;).find({}) Use pymongo to connect with remote mongoDB def connectDB(): client = pymongo.MongoClient(&amp;#39;mongodb://username:password@remote_ip_address:port&amp;#39;) db = client[&amp;#39;database&amp;#39;] def get_collection(collection): &amp;#34;&amp;#34;&amp;#34; params: --- collection: string, is the db collection name of the data that wanted to get from current database.</description>
    </item>
    
    <item>
      <title>Flask(1): Introduction and Setup the Environment</title>
      <link>https://ffflora.github.io/posts/flask1/</link>
      <pubDate>Mon, 02 Dec 2019 23:08:11 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/flask1/</guid>
      <description>How to Run Flask by Command After installing/updating the flask package with $conda$, one could use the following command to run the scripts:
$ flask run # This command runs the app.py or wsgi.py under the current dir automatically. And user could find the server running on $http://localhost:5000$, the port by default is 5000.
If you are going to run the scripts other than the two filenames mentioned above, you need to specify the environment variable FLASK_APP by:</description>
    </item>
    
    <item>
      <title>Notes on Recommendation System</title>
      <link>https://ffflora.github.io/posts/recommendation-sys/</link>
      <pubDate>Wed, 20 Nov 2019 00:09:34 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/recommendation-sys/</guid>
      <description>What is a Recommendation System? Recommendation system helps people to find things, when the process of finding the information you need might be a little bit challenging, since there&amp;rsquo;s too many choices.
There are two types of recommendation engine:
 most popular (Non personalized: normally top-n algorithm) by features among all users -&amp;gt; this needs to classify the users into various segments. (personalized)  Techniques Non-personalized:  Popularity Frequency count Mean Rating Association Rule Mining  Apriori algorithm: beers and diapers   Pros: no need to analyze the personalized data</description>
    </item>
    
    <item>
      <title>Notes on the paper (NLP): Character-level ConvNets for Text Classification</title>
      <link>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</link>
      <pubDate>Tue, 05 Nov 2019 22:14:01 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</guid>
      <description>Background Knowledge  CNN One-hot encoding  Some highlights of the paper When trained on large-scale datasets, deep ConvNets do not require the knowledge of words, in addition to the conclusion from previous research that ConvNets do not require the knowledge about the syntactic or semantic structure of a language. (Chinese News corpus convert to pinyin first, and then apply this model achieves only 10 something testing error.)
Dataset size forms a dichotomy between traditional and ConvNets models: the larger datasets tend to perform better.</description>
    </item>
    
    <item>
      <title>Notes on the Paper (NLP): Skip-thought Vectors</title>
      <link>https://ffflora.github.io/posts/skip-thoughts-paper/</link>
      <pubDate>Sun, 27 Oct 2019 01:21:49 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/skip-thoughts-paper/</guid>
      <description>Paper
Code
Background Knowledge Sentence representation
Bag of words representation
Sen2Vec/Doc2Vec
Some highlights of the paper Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.
The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences.</description>
    </item>
    
    <item>
      <title>Set Up Network and HTTP Load Balancers in GCP</title>
      <link>https://ffflora.github.io/posts/network-and-http/</link>
      <pubDate>Sat, 14 Sep 2019 22:30:48 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/network-and-http/</guid>
      <description>This note is based on GCP Qwiklab Essentials.
Create multiple web server instances To simulate serving from a cluster of machines, create a simple cluster of Nginx web servers to serve static content using Instance Templates and Managed Instance Groups. Instance Templates define the look of every virtual machine in the cluster (disk, CPUs, memory, etc). Managed Instance Groups instantiate a number of virtual machine instances using the Instance Template.</description>
    </item>
    
    <item>
      <title>How to Setup Kubernetes in GCP</title>
      <link>https://ffflora.github.io/posts/kubernetes/</link>
      <pubDate>Sat, 14 Sep 2019 21:02:06 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/kubernetes/</guid>
      <description>Creating a Kubernetes Engine cluster gcloud container clusters create [CLUSTER-NAME] Get authentication credentials for the cluster gcloud container clusters get-credentials [CLUSTER-NAME] Deploying an application to the cluster use kubectl run command to create a new Deployment
kubectl run hello-server --image=gcr.io/google-samples/hello-app:1.0 --port 8080 This Kubernetes command creates a Deployment object that represents hello-app. In this command:
 --image specifies a container image to deploy. In this case, the command pulls the example image from a Google Container Registry bucket.</description>
    </item>
    
    <item>
      <title>How to be a Kaggle Master?</title>
      <link>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</link>
      <pubDate>Thu, 05 Sep 2019 13:27:11 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</guid>
      <description>How to be a Kaggle Master Kaggle Combo x3:
Feature Engineering, Model Tuning, Model Ensemble Data Preprocessing: Missing values imputation:  Numeric Features  Impute with mean for normal distributed feature Impute with median for skewed distribution (reduce the impacts of outliers)  Categorical Features  Majority Imputation  Supervised Learning Imputation  Regression/Classification  XGBoost/LightGBM:  Missing values are gracefully treated by considering missing values as candidate for tree splitting point.</description>
    </item>
    
    <item>
      <title>Use Auto-completion in gcloud</title>
      <link>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</link>
      <pubDate>Wed, 28 Aug 2019 00:02:53 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</guid>
      <description>This notes is from Qwiklabs GCP Essentials.
Auto-completion gcloud interactive has auto prompting for commands and flags, and displays inline help snippets in the lower section as the command is typed.
Static information, like command and sub-command names, and flag names and enumerated flag values, are auto-completed using dropdown menus.
Install the beta components:
gcloud components install beta Enter the gcloud interactive mode:
gcloud beta interactive When using the interactive mode, click on the Tab key to complete file path and resource arguments.</description>
    </item>
    
    <item>
      <title>How to read csv files under .gz in Kaggle kernel?</title>
      <link>https://ffflora.github.io/posts/read-gz-in-kaggle/</link>
      <pubDate>Tue, 27 Aug 2019 00:23:55 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/read-gz-in-kaggle/</guid>
      <description>It took me long time to figure it out.
Say if the files&amp;rsquo; directory in the Kaggle kernel looks like this:
competitive-data-science-predict-future-sales sales_train.csv.gz sales_train.csv When I try to list all the files in the directory, I realize that there&amp;rsquo;s no need to unzip the .gz file in order to get the .csv files, since
import os data_dir = &amp;#39;/kaggle/input/competitive-data-science-predict-future-sales&amp;#39; os.listdir(data_dir) the output is:
[&amp;#39;test.csv&amp;#39;, &amp;#39;item_categories.csv&amp;#39;, &amp;#39;sales_train.csv&amp;#39;, &amp;#39;sample_submission.csv&amp;#39;, &amp;#39;items.csv&amp;#39;, &amp;#39;shops.csv&amp;#39;] Thus in order to use the .</description>
    </item>
    
  </channel>
</rss>