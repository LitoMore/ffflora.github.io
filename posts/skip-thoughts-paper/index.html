<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Flora Jiang">
    <meta name="description" content="Flora&#39;s personal website">
    <meta name="keywords" content="blog,data,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Notes on the Paper (NLP): Skip-thought Vectors"/>
<meta name="twitter:description" content="Paper
Code
Background Knowledge Sentence representation
Bag of words representation
Sen2Vec/Doc2Vec
Some highlights of the paper Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.
The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences."/>

    <meta property="og:title" content="Notes on the Paper (NLP): Skip-thought Vectors" />
<meta property="og:description" content="Paper
Code
Background Knowledge Sentence representation
Bag of words representation
Sen2Vec/Doc2Vec
Some highlights of the paper Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.
The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ffflora.github.io/posts/skip-thoughts-paper/" />
<meta property="article:published_time" content="2019-10-27T01:21:49-07:00" />
<meta property="article:modified_time" content="2019-10-27T01:21:49-07:00" />


    
      <base href="https://ffflora.github.io/posts/skip-thoughts-paper/">
    
    <title>
  Notes on the Paper (NLP): Skip-thought Vectors · Flora&#39;s
</title>

    
      <link rel="canonical" href="https://ffflora.github.io/posts/skip-thoughts-paper/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://ffflora.github.io/css/coder.min.4c6fcdf76ee3d92d0bdf8069e772433840f81d68ed1e743b0d7a09ca0cd4421d.css" integrity="sha256-TG/N927j2S0L34Bp53JDOED4HWjtHnQ7DXoJygzUQh0=" crossorigin="anonymous" media="screen" />
    

    

    

    

    
    
    <link rel="icon" type="image/png" href="https://ffflora.github.io/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://ffflora.github.io/img/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.57.2" />
  </head>

  <body class=" ">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://ffflora.github.io/">
      Flora&#39;s
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ffflora.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ffflora.github.io/resume.pdf">Resume</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ffflora.github.io/cn/">??</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Notes on the Paper (NLP): Skip-thought Vectors</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2019-10-27T01:21:49-07:00'>
                October 27, 2019
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              3 minutes read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://ffflora.github.io/categories/data-science/">Data Science</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="https://ffflora.github.io/tags/nlp/">NLP</a>
      <span class="separator">•</span>
    <a href="https://ffflora.github.io/tags/paper/">paper</a>
      <span class="separator">•</span>
    <a href="https://ffflora.github.io/tags/algorithm/">algorithm</a></div>

        </div>
      </header>

      <div>
        

<p><a href="https://arxiv.org/abs/1506.06726">Paper</a></p>

<p><a href="https://github.com/sanyam5/skip-thoughts">Code</a></p>

<h1 id="background-knowledge">Background Knowledge</h1>

<p>Sentence representation</p>

<p>Bag of words representation</p>

<p>Sen2Vec/Doc2Vec</p>

<h1 id="some-highlights-of-the-paper">Some highlights of the paper</h1>

<p>Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.</p>

<p>The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences.</p>

<p>Since the goal is to evaluate skip-thoughts as a general feature extractor, we keep text pre-processing to a minimum.   When encoding new sentences, no additional preprocessing is done other than basictokenization. This is done to test the robustness of our vectors.</p>

<h3 id="sentence-representation">Sentence Representation</h3>

<h4 id="one-hot-word-representation">One-hot word representation</h4>

<p>words in a sentence are considered as separated, so in terms of sentence representation, one-hot doesn&rsquo;t take a fully consideration that there might be information hidden in the structure of the sentences.</p>

<h4 id="weighted-word-embedding-based-word-representation">Weighted word embedding based word representation</h4>

<p>TFIDF</p>

<p>SIF</p>

<h4 id="nn-language-model-based-sentence-representation">NN Language Model based sentence representation</h4>

<p>uses unsupervised text corpus, and uses the co-occurrence between the words (共现信息), could be trained in large scale corpus.</p>

<p><strong>Pro</strong>: uses unsupervised corpus, low in cost; uses language model to learn information</p>

<p><strong>Cons</strong>: it ignores the hidden semantic connection (语义联系) behind the sentences, which is not reasonable.</p>

<h4 id="paraphrased-sentences-pairs-based-sentence-representation">Paraphrased sentences pairs based sentence representation</h4>

<p>A is B&rsquo;s father</p>

<p>B is A&rsquo;s son.</p>

<p>paraphrase of each other.</p>

<p>There are good resources of paraphrase sentences corpus out there, and they are used to train language models. corpus could be machine translated sentences; could model the relationships between the sentences.</p>

<p><strong>Pros</strong>: model the similarity and dissimilarity relationship between the sentences.</p>

<p><strong>Cons</strong>: only models out the correlation, but ignores the complex sematic connection.</p>

<h4 id="skip-thought">Skip-thought</h4>

<p>uses the large scale unsupervised corpus to model the relationship/connection between the sentences.</p>

<hr />

<h2 id="motivation">Motivation</h2>

<p>Bert is also an application of sentence representation tool.</p>

<p>Between the sentences, there are always sematic connections, is it possible to predict <strong>one</strong> sentence before and after the <strong>center sentence</strong>?</p>

<h3 id="skip-gram">Skip-Gram</h3>

<p>For example, there are some words:</p>

<p><u>like deep</u> <strong>learning</strong> <u>and NLP</u></p>

<p>which <strong>learning</strong> is the center word, <u>like deep</u>  and <u>and NLP</u> are the output context words.</p>

<p><strong>Skip-thought</strong> uses the same idea, the only difference is that the subject here is sentence level instead of word level.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Innovation of this paper:</p>

<ol>
<li>It provides a new method for sentence representation, which it

<ul>
<li>considered the relationships between sentences, and</li>
<li>it uses unsupervised corpus</li>
</ul></li>
<li>it proves that there exist a model, such that if it has been trained <strong>once</strong>, it could be uses for <strong>multiple</strong> times.</li>
<li>The experiments&rsquo; results are in great detail, which helps for later research.</li>
</ol>

<hr />

<h2 id="reproduce-the-paper-pytorch">Reproduce the Paper (Pytorch)</h2>

<p>It&rsquo;s hard to reproduce this paper, since the model itself was trained by a large scale dataset, and it also requires a highly computational resources (2080 GPU in this case), which might take 2-3 months to reproduce and get the similar results.</p>

<p><a href="https://github.com/sanyam5/skip-thoughts">Code here</a></p>

      </div>

      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "ffflora-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
      <p>Happy Analyzing!</p>
    
    
    
    
  </section>
</footer>

    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-146589116-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>

</html>
