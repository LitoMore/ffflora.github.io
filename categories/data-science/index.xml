<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on Flora&#39;s</title>
    <link>https://ffflora.github.io/categories/data-science/</link>
    <description>Recent content in Data Science on Flora&#39;s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Mar 2020 17:08:10 -0700</lastBuildDate>
    
	<atom:link href="https://ffflora.github.io/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>读书笔记：《改善 Python 程序的 91 个建议》(1)</title>
      <link>https://ffflora.github.io/cn/solid-python/</link>
      <pubDate>Wed, 18 Mar 2020 17:08:10 -0700</pubDate>
      
      <guid>https://ffflora.github.io/cn/solid-python/</guid>
      <description>改善 Python 程序的 91 个建议(1) Content: Chapter 1 建议1：理解Pythonic概念
建议2：编写Pythonic代码
建议3：理解Python与C语言的不同之处
建议4：在代码中适当添加注释
建议5：通过适当添加空行使代码布局更为优雅、合理
建议6：编写函数的4个原则
建议7：将常量集中到一个文件
Chapter 2 建议8：利用assert语句来发现问题
建议9：数据交换值的时候不推荐使用中间变量
建议10：充分利用Lazy evaluation的特性
建议11：理解枚举替代实现的缺陷
建议12：不推荐使用type来进行类型检查
建议13：尽量转换为浮点类型后再做除法
建议14：警惕eval()的安全漏洞
建议15：使用enumerate()获取序列迭代的索引和值
建议16：分清==与is的适用场景
建议17：考虑兼容性，尽可能使用Unicode
建议18：构建合理的包层次来管理module
Chapter 3 建议19：有节制地使用from&amp;hellip;import语句
建议20：优先使用absolute import来导入模块
建议21：i+=1不等于++i
建议22：使用with自动关闭资源
建议23：使用else子句简化循环（异常处理）
建议24：遵循异常处理的几点基本原则
建议25：避免finally中可能发生的陷阱
建议26：深入理解None，正确判断对象是否为空
建议27：连接字符串应优先使用join而不是+
建议28：格式化字符串时尽量使用.format方式而不是%
建议29：区别对待可变对象和不可变对象
建议30：[]、()和{}：一致的容器初始化形式
建议31：记住函数传参既不是传值也不是传引用
建议32：警惕默认参数潜在的问题
建议33：慎用变长参数
建议34：深入理解str()和repr()的区别
建议35：分清staticmethod和classmethod的适用场景
Chapter 4 建议36：掌握字符串的基本用法
建议37：按需选择sort()或者sorted()
建议38：使用copy模块深拷贝对象
建议39：使用Counter进行计数统计
建议40：深入掌握ConfigParser
建议41：使用argparse处理命令行参数
建议42：使用pandas处理大型CSV文件
建议43：一般情况使用ElementTree解析XML
建议44：理解模块pickle优劣
建议45：序列化的另一个不错的选择——JSON
建议46：使用traceback获取栈信息
建议47：使用logging记录日志信息
建议48：使用threading模块编写多线程程序
建议49：使用Queue使多线程编程更安全
Chapter 5 建议50：利用模块实现单例模式
建议51：用mixin模式让程序更加灵活</description>
    </item>
    
    <item>
      <title>Notes on the paper(NLP): Efficient Estimation of Word Representations in Vector Space</title>
      <link>https://ffflora.github.io/posts/efficient-estimation/</link>
      <pubDate>Fri, 28 Feb 2020 10:25:43 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/efficient-estimation/</guid>
      <description>Background Knowledge Machine Learning
Calculus
Programming Skills: C++, PyTorch
Language Model: sentence = {x1,x2,....,xn}
use frequency of the corpus instead of the probabilities:
p(xi) = count(xi)/N
p(xi-1,xi) = count(xi-1,xi)/N
Use conditional probability p(xi|xi-1):
p(xi|xi-1) = count(xi-1,xi)/count(xi)
Markov chain k-gram model
Sigmod Gradient Descent Softmax Distributed Representation The origin of NLP deep learning: features.
One-hot representation Easy to represent, but the problems are
 More words, higher the dimension. There are no connections between the words.</description>
    </item>
    
    <item>
      <title>Notes on Recommendation System</title>
      <link>https://ffflora.github.io/posts/recommendation-sys/</link>
      <pubDate>Wed, 20 Nov 2019 00:09:34 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/recommendation-sys/</guid>
      <description>What is a Recommendation System? Recommendation system helps people to find things, when the process of finding the information you need might be a little bit challenging, since there&amp;rsquo;s too many choices.
There are two types of recommendation engine:
 most popular (Non personalized: normally top-n algorithm) by features among all users -&amp;gt; this needs to classify the users into various segments. (personalized)  Techniques Non-personalized:  Popularity Frequency count Mean Rating Association Rule Mining  Apriori algorithm: beers and diapers   Pros: no need to analyze the personalized data</description>
    </item>
    
    <item>
      <title>Notes on the paper (NLP): Character-level ConvNets for Text Classification</title>
      <link>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</link>
      <pubDate>Tue, 05 Nov 2019 22:14:01 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</guid>
      <description>Background Knowledge  CNN One-hot encoding  Some highlights of the paper When trained on large-scale datasets, deep ConvNets do not require the knowledge of words, in addition to the conclusion from previous research that ConvNets do not require the knowledge about the syntactic or semantic structure of a language. (Chinese News corpus convert to pinyin first, and then apply this model achieves only 10 something testing error.)
Dataset size forms a dichotomy between traditional and ConvNets models: the larger datasets tend to perform better.</description>
    </item>
    
    <item>
      <title>Notes on the Paper (NLP): Skip-thought Vectors</title>
      <link>https://ffflora.github.io/posts/skip-thoughts-paper/</link>
      <pubDate>Sun, 27 Oct 2019 01:21:49 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/skip-thoughts-paper/</guid>
      <description>Paper
Code
Background Knowledge Sentence representation
Bag of words representation
Sen2Vec/Doc2Vec
Some highlights of the paper Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.
The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences.</description>
    </item>
    
    <item>
      <title>Set Up Network and HTTP Load Balancers in GCP</title>
      <link>https://ffflora.github.io/posts/network-and-http/</link>
      <pubDate>Sat, 14 Sep 2019 22:30:48 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/network-and-http/</guid>
      <description>This note is based on GCP Qwiklab Essentials.
Create multiple web server instances To simulate serving from a cluster of machines, create a simple cluster of Nginx web servers to serve static content using Instance Templates and Managed Instance Groups. Instance Templates define the look of every virtual machine in the cluster (disk, CPUs, memory, etc). Managed Instance Groups instantiate a number of virtual machine instances using the Instance Template.</description>
    </item>
    
    <item>
      <title>How to Setup Kubernetes in GCP</title>
      <link>https://ffflora.github.io/posts/kubernetes/</link>
      <pubDate>Sat, 14 Sep 2019 21:02:06 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/kubernetes/</guid>
      <description>Creating a Kubernetes Engine cluster gcloud container clusters create [CLUSTER-NAME] Get authentication credentials for the cluster gcloud container clusters get-credentials [CLUSTER-NAME] Deploying an application to the cluster use kubectl run command to create a new Deployment
kubectl run hello-server --image=gcr.io/google-samples/hello-app:1.0 --port 8080 This Kubernetes command creates a Deployment object that represents hello-app. In this command:
 --image specifies a container image to deploy. In this case, the command pulls the example image from a Google Container Registry bucket.</description>
    </item>
    
    <item>
      <title>Resnet 算法详解</title>
      <link>https://ffflora.github.io/cn/resnet/</link>
      <pubDate>Fri, 06 Sep 2019 18:08:34 -0700</pubDate>
      
      <guid>https://ffflora.github.io/cn/resnet/</guid>
      <description>ResNet 详解 The Resnet Paper is here: Deep Residual Learning for Image Recognition
Netscope CNN Analyzer
网络加深性能并不一定使模型变得更强，层数更多并不总是有更准确的结果，解决方法之一是 可以构造一个性能与浅层模型相当的结构。Residual function 顾名思义就是残差，是根据论文里 Figure2, y = F(x) + x, 需要学习的是 F, F(x) = y - x, F 就是 residual.
残差学习？残差网络？ 残差学习模块有两个分支：一是左侧的残差函数，二是右侧的对输入的恒等映射。这两个分支经过对应元素的相加之后，再经过一个非线性的变换 ReLU 激活函数，从而形成整个残差学习模块。将若干个残差模块堆叠，就成为了 残差网络。
ResNet 可以构建很深的神经网络，比如 ResNet -50/101/152 等。
ResNet - v2 ResNet 后期推出了更多其它的链接方式，但是实验之后发现还是没有 identity shortcut 好。
Pre-activation Residual Module:  原先 Residual Block 是 CBR(Conv, BN, ReLU) 结构 BRC(BN, ReLU, Conv) 结构 activate 在 conv 之前。被称作为 pre-activation 结构。  ResNeXt ResNeXt 转向对神经网络拓扑设计的研究，对 block 堆叠的策略；</description>
    </item>
    
    <item>
      <title>How to be a Kaggle Master?</title>
      <link>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</link>
      <pubDate>Thu, 05 Sep 2019 13:27:11 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</guid>
      <description>How to be a Kaggle Master Kaggle Combo x3:
Feature Engineering, Model Tuning, Model Ensemble Data Preprocessing: Missing values imputation:  Numeric Features  Impute with mean for normal distributed feature Impute with median for skewed distribution (reduce the impacts of outliers)  Categorical Features  Majority Imputation  Supervised Learning Imputation  Regression/Classification  XGBoost/LightGBM:  Missing values are gracefully treated by considering missing values as candidate for tree splitting point.</description>
    </item>
    
    <item>
      <title>Use Auto-completion in gcloud</title>
      <link>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</link>
      <pubDate>Wed, 28 Aug 2019 00:02:53 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</guid>
      <description>This notes is from Qwiklabs GCP Essentials.
Auto-completion gcloud interactive has auto prompting for commands and flags, and displays inline help snippets in the lower section as the command is typed.
Static information, like command and sub-command names, and flag names and enumerated flag values, are auto-completed using dropdown menus.
Install the beta components:
gcloud components install beta Enter the gcloud interactive mode:
gcloud beta interactive When using the interactive mode, click on the Tab key to complete file path and resource arguments.</description>
    </item>
    
    <item>
      <title>How to read csv files under .gz in Kaggle kernel?</title>
      <link>https://ffflora.github.io/posts/read-gz-in-kaggle/</link>
      <pubDate>Tue, 27 Aug 2019 00:23:55 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/read-gz-in-kaggle/</guid>
      <description>It took me long time to figure it out.
Say if the files&amp;rsquo; directory in the Kaggle kernel looks like this:
competitive-data-science-predict-future-sales sales_train.csv.gz sales_train.csv When I try to list all the files in the directory, I realize that there&amp;rsquo;s no need to unzip the .gz file in order to get the .csv files, since
import os data_dir = &amp;#39;/kaggle/input/competitive-data-science-predict-future-sales&amp;#39; os.listdir(data_dir) the output is:
[&amp;#39;test.csv&amp;#39;, &amp;#39;item_categories.csv&amp;#39;, &amp;#39;sales_train.csv&amp;#39;, &amp;#39;sample_submission.csv&amp;#39;, &amp;#39;items.csv&amp;#39;, &amp;#39;shops.csv&amp;#39;] Thus in order to use the .</description>
    </item>
    
  </channel>
</rss>