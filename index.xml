<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Flora&#39;s</title>
    <link>https://ffflora.github.io/</link>
    <description>Recent content on Flora&#39;s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 29 Feb 2020 19:18:24 -0800</lastBuildDate>
    
	<atom:link href="https://ffflora.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>读书笔记：《癌症·真相》</title>
      <link>https://ffflora.github.io/cn/cancer/</link>
      <pubDate>Sat, 29 Feb 2020 19:18:24 -0800</pubDate>
      
      <guid>https://ffflora.github.io/cn/cancer/</guid>
      <description>癌症·真相：医生也在读
◆ 癌症如何导致死亡
癌症致死有时候并不是某一个器官衰竭造成的，而是由于系统性衰竭。有很多癌症，由于现在还不清楚的原因，会导致患者体重迅速下降，肌肉和脂肪都迅速丢失，无论患者吃多少东西，输多少蛋白质都没用，这个现象叫“恶病质”（cachexia）。恶病质现在无药可治，是不可逆的。由于肌肉和脂肪对整个机体的能量供应、内分泌调节至关重要，出现恶病质的癌症患者很快会出现系统性衰竭而死亡。
◆ 癌症为何如此难治
例如，传统化疗药物能够杀死快速生长的细胞，对癌细胞当然很有用，但是很可惜，我们身体中有很多正常细胞也是在快速生长的，比如头皮下的毛囊细胞。毛囊细胞对头发生长至关重要，化疗药物杀死癌细胞的同时，也杀死了毛囊细胞，这是为什么化疗的患者头发都会掉光。负责造血和维持免疫系统的造血干细胞也会被杀死，因此化疗患者的免疫系统会非常弱，极容易感染。消化道上皮细胞也会被杀死，于是患者严重拉肚子、没有食欲，等等。
我们知道，癌症是由于基因突变造成的，最近一项系统性基因测序研究表明，肺癌患者平均每人突变数目接近5000个！每个人突变的组合都不同，每个患者的基因组都是特异的。
因为癌症的多样性，药厂几乎注定每次只能针对很少的患者研发药物，每一个新药的开发成本是多少呢？10年+20亿美金！这样大的时间、金钱投入，导致我们进展缓慢，要攻克所有的癌症，即使不是遥遥无期，也是任重道远。
◆ 儿童癌症，为了中国的未来
第一，和成人癌细胞动则有上千个基因突变不同，儿童癌症的基因突变往往很少，一般只有几个，因此癌症产生抗药性的可能性较低；第二，和传统想法不同，对儿童癌症患者使用的化疗和放疗的剂量按体形比例来说往往超过了成年人，这是由于儿童组织修复能力比较强，能够忍受更多的化疗和放疗带来的副作用。这两点是儿童癌症的治疗成功率远远高于成人癌症的重要原因。
◆ 雾霾能引起儿童癌症吗
说科普宣传一定要带有人文关怀
好的科普文章一定是站在读者角度来写的，而不应该站在科学家的角度来写
除去本身的遗传因素，卵子中出现新基因突变的概率在35～40岁以后会指数级提高，多1岁就多1倍风险，因此大家在有条件的情况下应该尽量在35岁之前生宝宝，而大龄孕妇则一定要做好孕前和孕期检测和监测。
幸运的是，卵子或者精子有突变的整体概率非常低，而且即便有突变，生物体进化出的保护功能很多时候会让问题胚胎流产，防止有缺陷小孩的出生。我一向觉得只要不是习惯性，流产很可能不是坏事。
◆ 抗癌药物的三次革命
但是和放疗一样，化疗药物的死穴是它们本身并不能区分恶性细胞还是正常细胞，因此化疗药物在杀死癌细胞的同时也会杀死大量人体正常的需要分裂的干细胞，这就是为什么化疗对细胞生长比较旺盛的骨髓细胞、肝细胞、肠胃表皮细胞等都有非常严重的副作用。临床上化疗药物的使用剂量必须受到严格控制：药物太少不能起到杀死癌细胞的作用，药物太多会产生过于严重的副作用，对患者造成“不可逆伤害”，甚至死亡。
有个合适例子帮助大家理解化疗药物的毒副作用：砒霜（三氧化二砷）。这个帮助潘金莲和西门大官人毒杀了武大郎的臭名昭著的古代毒药，现在有个洋名字：Trisenox，它被FDA批准用于治疗白血病，在美国临床上发光发热！
◆ CAR-T，治愈癌症新武器
CAR-T也不是完美的，患者接受CAR-T疗法有一个巨大的临床风险：细胞因子风暴，也叫细胞因子释放综合征。产生的原因是T细胞在杀死其他细胞比如细菌、病毒的时候，会释放很多蛋白，叫细胞因子，它们的作用是激活更多的免疫细胞来一起对抗这些病原体，这种正反馈机制保证了对病原体的快速清除。这在临床上就是炎症反应，平时我们扁桃体发炎等就和这个有关。由于CAR-T杀癌细胞实在是太快太有效了，于是瞬间在局部产生超大量的细胞因子，引起惊人的免疫反应，这就是细胞因子风暴。临床表现就是患者超高烧不退，如果控制不好，很有可能就救不过来了。
◆ 谋财不害命，国内免疫疗法现状
①国内目前广泛使用的“免疫疗法”（主要是CIK-DC细胞疗法）和最近临床上证明有效的“免疫疗法”不是一种东西；②“CIK-DC免疫疗法”是在炒欧美十多年前的冷饭，这种疗法在欧美临床实验失败，已经被淘汰了。③国内名目繁多的“免疫疗法”没有任何一种经过严格的临床测试。
狭义地来讲，现在常说的“免疫疗法”主要分为两类，第一类是细胞疗法，就是通过直接向患者输入激活的免疫细胞来治疗癌症；第二类是干预疗法，就是通过药物或者疫苗来激活患者体内的免疫细胞来治疗癌症。
◆ 肺癌，癌症第一杀手
最近的一篇研究论文第一次系统性地对比了吸烟和不吸烟肺癌的DNA，发现了令人震惊的结论：虽然癌症表面看起来相似，但吸烟者肺癌中基因突变的数目是不吸烟者的10倍还多！不吸烟或偶尔吸烟者的肺癌基因平均突变数是18，最多的一个也仅是22个，而长期吸烟者的平均基因突变数是209，最多的一个吸烟患者高达1363！
吸烟者肺癌细胞之所以突变多，有两个主要原因，一是烟雾中含有超过50种强致癌物质。所谓的强致癌物就是能诱导基因突变的化合物，因此吸烟者癌症突变多一点都不奇怪。二是烟雾对肺部的损伤很大，会导致组织坏死，人体本身会努力去修复这样的组织，主要办法就是诱导干细胞生长分裂，来产生新细胞以修补坏死组织，长期吸烟就会产生反复的“破坏—修复—破坏—修复”。如我在前面提到的，任何一次细胞的生长分裂都有产生突变的可能性，因此这种长期的破坏—修复循环也会积累大量的基因突变。慢性乙肝病毒导致肝癌也是类似的原因。
中国越发严重的雾霾是否导致肺癌由于数据难以收集，还存在争议，但在我看来，即使雾霾中不含任何的强致癌物，仅仅凭借对肺组织的慢性损伤，刺激产生和吸烟类似的“破坏—修复”循环，一定会积累基因突变，长此以往，雾霾促进肺癌的产生只是时间问题。我们为什么关心基因突变的数目？因为癌症基因突变越多，对药物产生抗药性的能力越强！
第二，吸烟和不吸烟者肺癌的基因突变种类不同。
对于每个癌症，虽然都有十几到几千个突变，但是其中通常都有一个主要的突变，对癌症生长起到至关重要的作用，学术上我们称这类重要突变为“驱动突变”或“司机突变”（driver mutation），因为它们控制了癌症的发展和走向。肺癌中最常见的“驱动突变”基因有3个：KRAS、EGFR和ALK，吸烟者肺癌中主要是KRAS突变，而不吸烟者肺癌则主要是EGFR和ALK突变。
◆ 雾霾和肺癌，到底什么关系
雾霾能导致肺癌，从科学上有两大原因。第一，雾霾中含有致癌化学物质。雾霾或者PM2.5中的成分非常复杂，各地雾霾成分都不一样，但都包括了成百上千的各类化学物质。这里面有一些是和癌症有联系的，比如多环芳香烃、致癌重金属、二氧化硫、氮氧化物等。长期大量吸入这类化合物，可以导致基因突变，增加肺癌发生几率。第二，雾霾中的细小颗粒会造成长期慢性肺部伤害。我在前面已经说过，癌症发生是因为基因突变。去除先天遗传因素，基因突变发生的概率和细胞分裂的次数直接相关。每一次的细胞分裂，都有一定概率发生基因突变，因此细胞分裂次数越多，得癌症几率越大。这就是为什么癌症患者主要是老年人。因为生存时间越久，细胞需要分裂的次数越多，按照概率，得癌症的机会就会更高。重度空气污染情况下，即使不考虑致癌物，吸入的各种物理颗粒和化学物质也会造成肺部细胞损伤，而为了修复这种损伤，肺部细胞就需要分裂增生。因此，长期的空气污染会造成肺部反复的“损伤—修复—损伤—修复”循环，导致大量细胞分裂，从而增加肺癌发生概率。简单来说就是空气污染会导致肺部加速老化，而肺癌就是肺部老化后最危险的后果之一。我们谈雾霾的时候经常提到的指标是PM2.5，大家也最关注这个指标。它为什么重要呢？PM2.5是指直径在2.5微米以下的悬浮颗粒物，它只有头发直径的几十分之一，极容易进入肺部，而且能进入到很深的支气管。实际上，雾霾中还有各式各样大大小小的颗粒都有可能对肺部造成伤害，既有PM10这种稍微大一点的，也有比PM2.5小很多没有名字的超级微小颗粒。
◆ EGFR突变肺癌的靶向药物治疗
一线药物指患者使用的第一种药物，现在一般是化疗
肺癌患者根据癌细胞形态分为“小细胞肺癌”和“非小细胞肺癌”，约85%肺癌患者都是“非小细胞肺癌”。现在非小细胞肺癌患者或多或少都会做基因检测，来看看是否适用新型靶向药，而非小细胞肺癌中最常见且有针对性靶向药物的突变就是EGFR突变。
肺癌中有EGFR突变的主流人群：亚裔、女性、中年、无吸烟史、非小细胞腺癌。当然这不是绝对的，只是说存在EGFR突变亚裔比其他族裔的比例高、女性比男性比例高、中青年比老年比例高、不吸烟的比吸烟的比例高、非小细胞腺癌比其他肺癌比例高。吸烟肺癌患者中的EGFR突变比例相对较低
◆ ALK突变肺癌的靶向药物治疗
对于癌症的基因检测，目的不是为了知道基因突变，而是知道突变后能指导使用不同的靶向药物，这才是基因检测的临床价值。
◆ 那些坊间关于癌症的传言
红烧转基因荧光双眼皮鲨鱼和红烧青藏高原纯净无污染鲤鱼，吃到肚子里都是一样的；转基因五彩玉米饭和黑土地五谷杂粮营养饭，吃到肚子里也都是一样的。
◆ 高大上的防癌体检靠谱吗
PET-CT的主要价值是用于局部癌症（比如肺癌）患者的确诊和复发的监控，美国权威机构明确反对使用全身PET-CT给健康人体检，一是它用在普通大众身上有很高的“假阴性”和“假阳性”概率，对于发现早期癌症几乎没有价值；二是因为PET-CT本身就致癌，因此普通人根本就不应该用。
临床上使用PET-CT多数时候都只专注看一个地方，比如肺癌患者就只看肺部、脑瘤患者就只看脑部，必须知道看哪里，才能看出区别，如果你都不知道看哪里，看PET-CT基本就是抓瞎。同时，PET-CT对不同癌症种类敏感度不同，膀胱癌、前列腺癌等常见癌症很难通过全身PET-CT发现，因此，这个测试有很多“假阴性”，也就是说有癌症查不出来
而做一次PET-CT就大概等于在海边晒10年的太阳！你没看错，是10年！事实上，做完PET-CT的患者由于体内含有放射性物质，按规定都需要和家人隔离一小段时间，不能接触孕妇、婴儿和小孩，而这个重要信息在很多大力推荐PET-CT体检的地方也被刻意忽略了。
发来用于癌症患者确诊和监测的，而不适宜于普通大众
◆ 日常生活中哪些辐射致癌
首先，“可能致癌物”的意思是“目前还证明不了它致癌，但值得继续关注”。
◆ 带爸爸来美国看病
其实对于癌症患者和家属来说，最可怕的不是癌症这个病，而是生活里挥之不去的对于未知的恐惧的阴霾。我不由得想到那句著名的话——“偶尔能治愈，常常在帮助，总是去安慰”，用来形容我们这次看病经历最贴切不过了。</description>
    </item>
    
    <item>
      <title>Roadmap </title>
      <link>https://ffflora.github.io/cn/roadmap/</link>
      <pubDate>Fri, 28 Feb 2020 12:02:09 -0800</pubDate>
      
      <guid>https://ffflora.github.io/cn/roadmap/</guid>
      <description>“先看目标市场。要填写这一项，就要求产品经理懂得如何做市场细分和确定目标客户，再看市场战略，这里又涉及产品生命周期管理的知识。虽然我这里写的只是引入期、成长期这样简单的文字，但是一个熟悉产品生命周期的产品经理，只看到这几个字的时候，就能立刻明白在不同的周期里应该用什么样的战略。
Rodamap 所要呈现出来的是一幅某个事物长远发展的图像。自然，Product Roadmap 所要求我们做的就是要呈现给我们的企业一个产品长远发展的构想。注意，这里说的是构想，而不是想象，更不是空想。构想是要有根据和体系的，它更偏重于事实在未来的一种呈现，这种构想很大程度上是可以变为现实的。具体到Product Roadmap，产品经理就要告诉企业以下信息：
● 所属产品线
● 产品名称
● 目标市场
● 市场战略
● 产品战略
● 核心卖点
● 价值主张
● 改善/增加的功能
● 所用技术
● 价格建议
&amp;mdash;《Yes! 产品经理》
最近在负责智能软件的roadmap，分为长期和短期两个部分。我们的智能软件是和智能硬件配套的，可以认为是智能硬件的操控软件，而智能硬件是通过销售，直接卖给最终消费者的（2C），然而规划中，遇到了一些迷惘的事。针对长期的，我个人认为应该要匹配智能硬件的发展和营销路线，因为用户最终的功能服务落地是通过智能硬件去体现的，而智能硬件的roadmap是基于大市场的分析而规划出来的，因此我觉得，从长期来说，应该是要去匹配智能硬件的roadmap的发展。而对于短期的部分，落实到最终的版本计划，我觉得应该是基于长期的某一产品阶段，针对用户体验反馈而进行优化迭代的，要以用户体验为中心，进行迭代。但是目前我们领导给我的思路和做事方式，是对于长期的部分，要让我不要去考虑智能硬件层，而只是从用户需求出发，看软件要做什么；而短期部分，是希望我基于长期的Roadmap，自己排出计划，要有自己的思考。领导给的方式与我自己的思考思路有很大的矛盾，我也试图说服领导，但是无用。想问下，真实的智能硬件的软件层面的Roadmap，应该是怎么个操作思路，谢谢了啊。
PS：智能硬件受众对象：偏高端人群；产品使用生命周期：2年。产品市场生命周期：3年。用户使用频次：1周1次。App操控使用占普通使用份额：50%。行业份额：国内No.1。
你们老板的思路是对的。智能硬件不是目的，虽然它最开始形成收入，用户买智能硬件本质上是需要硬件提供的软件功能和服务，软件功能很好地满足用户需求才会促使用户提升使用率（现在的使用频次是1周1次，比较少），有了使用率才能谈得上后续的转化。硬件只能卖一次，总不能靠保养维修来挣钱吧，除非你是卖车的。所以软件能否持续运营是很重要的命题，只要软件的功能很好地服务于用户的场景，用户不介意持续更换硬件，或者购买相应的配件。如果你在软件层发现了目标用户的痛点，进而可以对硬件发展提要求，这是合理的，但是上来就对硬件做大变化不太合适，一款硬件的各种沉没成本太高，随意切换版本有点浪费。Roadmap构建依赖于公司的资源、服务能力和技术研发敏捷度，你们产品的生命周期是2年，每年的更新次数是多少？计算一下你们的总资产周转率，产品的Roadmap本质是商业运转可能性，不能只关注产品研发本身。
&amp;mdash;《设计的思考：用户体验设计核心问答》
一个公司，一个团队，一个项目在不同阶段都会有不同的产品规划。产品规划中最核心的就是 RoadMap. RoadMap 指导整个产品的长期规划，指引众人共同努力的方向，也是产品经理管理需求的重要参考依据。通常情况下，大型公司会拟定未来一年的工作计划及安排，中型公司至少也会给出半年或者一个季度的安排，创业公司由于对市场验证及探索的周期较短，往往只能预估未来1个月的工作计划。适当的产品迭代周期，可以使用户感觉到产品依然是活跃的、处于发展的。无论是创业公司还是大型企业，拥有一套年度计划是非常重要和关键的。RoadMap 如同一个纲领，带着队伍有目标地前行，也代表着整个公司的业务走向、产品定位和战略目标。对于产品经理而言，正确把控公司战略，全面解读公司规划，做好火车头的工作是非常重要的。
根据战略目标，产品经理需要进一步给出 RoadMap，即产品功能规划，包括新功能增加和旧功能迭代。产品功能规划需要比战略目标更细腻，因为战略目标有时较粗略，可能仅仅是一个想法，或者部门领导人在某个领域的一个观点。作为产品经理，需要去市场验证这些既有信息，使之更接近市场需求，并给出能实现、能落地的实际需求点，让研发、设计、运营团队等参与者初步了解企业未来一段时间的目标和方向。产品经理制订产品功能规划的大原则是每个需求对应的目标和工作量都要可量化。至于具体要如何实现，还应结合公司自身的情况，以及人际关系，要利用有限的资源完成产品规划。适当的产品迭代周期，可以使用户感觉到产品在不断更新，会比长时间产品没有动静要好得多。合理地把控好迭代的步骤，根据产品的长期规划，反推小的版本迭代及功能上线，才是一种比较健康的产品推进方式。
产品的迭代速度不是越快越好，还要考虑产品的类型。产品在不同的生命周期（如引入期、成长期、成熟期），其迭代速度是不一样的。一般来说，产品处于引入期时，很多功能需要多次打磨，反复锤炼才能上线，所以迭代速度比较缓慢，迭代周期通常为2～3个月；产品处于成长期时，迭代周期要频繁些，比如3周一次；产品处于成熟期和衰退期时，产品迭代速度也会适当放缓，比如1个月更新一次。在迭代过程中，虽说有3类周期划分作为依据，但也并不是一成不变，如果在一个版本中还有需求没有做完，可以通过需求变更来进行调整，从而实现迭代周期内的版本上线。新人真正进入产品设计之前，都会花很长的时间去解决这样一个问题：我们应该制订一个怎样的产品功能规划使想法落地？我们永远要记住一点：需求和功能是相辅相成、不断成长的，我们随时随地都应该基于目标、问题去思考。因此，产品长期的发展迭代路线、分支功能的延伸、用户吸收策略、用户留存提升、活跃度提升、盈利模式等，都应提前准备和规划。
&amp;mdash;《从需求到产品：0岁产品经理进阶之道》</description>
    </item>
    
    <item>
      <title>Notes on the paper(NLP): Efficient Estimation of Word Representations in Vector Space</title>
      <link>https://ffflora.github.io/posts/efficient-estimation/</link>
      <pubDate>Fri, 28 Feb 2020 10:25:43 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/efficient-estimation/</guid>
      <description>Background Knowledge Machine Learning
Calculus
Programming Skills: C++, PyTorch
Language Model: sentence = {x1,x2,....,xn}
use frequency of the corpus instead of the probabilities:
p(xi) = count(xi)/N
p(xi-1,xi) = count(xi-1,xi)/N
Use conditional probability p(xi|xi-1):
p(xi|xi-1) = count(xi-1,xi)/count(xi)
Markov chain k-gram model
Sigmod Gradient Descent Softmax Distributed Representation The origin of NLP deep learning: features.
One-hot representation Easy to represent, but the problems are
 More words, higher the dimension. There are no connections between the words.</description>
    </item>
    
    <item>
      <title>React(1): Basics of React</title>
      <link>https://ffflora.github.io/posts/react-note1/</link>
      <pubDate>Tue, 28 Jan 2020 00:50:02 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/react-note1/</guid>
      <description>Basics of React (Most of the materials come from React Official Document) JSX Represents Objects Babel compiles JSX down to React.createElement() calls.
These two examples are identical:
const element = ( &amp;lt;h1 className=&amp;#34;greeting&amp;#34;&amp;gt; Hello, world! &amp;lt;/h1&amp;gt; ); const element = React.createElement( &amp;#39;h1&amp;#39;, {className: &amp;#39;greeting&amp;#39;}, &amp;#39;Hello, world!&amp;#39; ); React.createElement() performs a few checks to help you write bug-free code but essentially it creates an object like this:
// Note: this structure is simplified const element = { type: &amp;#39;h1&amp;#39;, props: { className: &amp;#39;greeting&amp;#39;, children: &amp;#39;Hello, world!</description>
    </item>
    
    <item>
      <title>Node.js Error Message Resolved</title>
      <link>https://ffflora.github.io/posts/node-error/</link>
      <pubDate>Fri, 24 Jan 2020 15:49:23 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/node-error/</guid>
      <description>So I had encountered these Error Messages when running a project:
npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! grpc@1.10.1 install: `node-pre-gyp install --fallback-to-build --library=static_library` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the grpc@1.10.1 install script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR!</description>
    </item>
    
    <item>
      <title>Conda Install Error Message Resolved</title>
      <link>https://ffflora.github.io/posts/conda-removeerror/</link>
      <pubDate>Thu, 16 Jan 2020 22:42:06 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/conda-removeerror/</guid>
      <description>I encountered with the error message today when I use conda install xxx :
RemoveError: &amp;#39;xxxxxx&amp;#39; is a dependency of conda and cannot be removed from conda&amp;#39;s operating environment. Solved by :
conda clean -all conda update --all</description>
    </item>
    
    <item>
      <title>Business Analyst ABCs and Interview Preparation</title>
      <link>https://ffflora.github.io/posts/ba/</link>
      <pubDate>Thu, 09 Jan 2020 22:02:18 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/ba/</guid>
      <description>Data is increasingly being considered an important asset within organization.
BA Oversee every process in typical E-commerce to look out for potential issues, problems and potential for optimization to boost the business performance.
 Under CFO or COO
 BI team
 Support various department:
  warehouse, UX design, marketing, operation, international
DA  Under CTO DA/DS team Support marketing/strategy/BI and work with technology closely.  Important Metrics and KPIs  Traffic: - Website  Conversion Rate</description>
    </item>
    
    <item>
      <title>MongoDB Useful Commands</title>
      <link>https://ffflora.github.io/posts/mongodb/</link>
      <pubDate>Thu, 09 Jan 2020 21:52:20 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/mongodb/</guid>
      <description>SQL vs MongoDB    SQL MongoDB     Table Collection   Row Document   Col Field   Primary Key ObjectId   Index Index   Embedded Table Embedded Table   Array Array    Common command lines
use dtbase #use some specific database db.collection.updateOne({tags:&amp;#39;abc&amp;#39;},{$set:{name:&amp;#39;flora&amp;#39;}}) db.collection.updatemMany({tags:&amp;#39;abc&amp;#39;},{$set:{name:&amp;#39;flora&amp;#39;}}) db.collection.insertOne({&amp;#39;name&amp;#39;:&amp;#39;Flora&amp;#39;,&amp;#39;age&amp;#39;:&amp;#39;17&amp;#39;}) db.getCollection(&amp;#39;collection_name&amp;#39;).find({}) Use pymongo to connect with remote mongoDB def connectDB(): client = pymongo.MongoClient(&amp;#39;mongodb://username:password@remote_ip_address:port&amp;#39;) db = client[&amp;#39;database&amp;#39;] def get_collection(collection): &amp;#34;&amp;#34;&amp;#34; params: --- collection: string, is the db collection name of the data that wanted to get from current database.</description>
    </item>
    
    <item>
      <title>Flask(1): Introduction and Setup the Environment</title>
      <link>https://ffflora.github.io/posts/flask1/</link>
      <pubDate>Mon, 02 Dec 2019 23:08:11 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/flask1/</guid>
      <description>How to Run Flask by Command After installing/updating the flask package with $conda$, one could use the following command to run the scripts:
$ flask run # This command runs the app.py or wsgi.py under the current dir automatically. And user could find the server running on $http://localhost:5000$, the port by default is 5000.
If you are going to run the scripts other than the two filenames mentioned above, you need to specify the environment variable FLASK_APP by:</description>
    </item>
    
    <item>
      <title>Notes on Recommendation System</title>
      <link>https://ffflora.github.io/posts/recommendation-sys/</link>
      <pubDate>Wed, 20 Nov 2019 00:09:34 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/recommendation-sys/</guid>
      <description>What is a Recommendation System? Recommendation system helps people to find things, when the process of finding the information you need might be a little bit challenging, since there&amp;rsquo;s too many choices.
There are two types of recommendation engine:
 most popular (Non personalized: normally top-n algorithm) by features among all users -&amp;gt; this needs to classify the users into various segments. (personalized)  Techniques Non-personalized:  Popularity Frequency count Mean Rating Association Rule Mining  Apriori algorithm: beers and diapers   Pros: no need to analyze the personalized data</description>
    </item>
    
    <item>
      <title>读书笔记：《走进内容推荐时代》</title>
      <link>https://ffflora.github.io/cn/rec-sys/</link>
      <pubDate>Tue, 19 Nov 2019 14:22:34 -0800</pubDate>
      
      <guid>https://ffflora.github.io/cn/rec-sys/</guid>
      <description>走进内容推荐时代 : 写给内容行业从业者的推荐分发入门书（市场先行版） ◆ 走近内容推荐 多种召回方式共同构建的视频候选集会被一并送进排序环节。在排序环节中，神经网络基于用户个体的特征和视频的特征对候选集进行打分，最后给用户返回得分靠前的十余个视频。
相对YouTube较为抽象简化的数据流图，Netflix（网飞）的架构图就更复杂一些了，但整体上仍然保持了离线模型训练、在线召回排序、更新用户画像与内容画像的基础结构。
离线模型训练、在线召回排序、更新用户画像与内容画像的基础结构。系统在实时响应用户请求的在线层和负责数据处理、模型训练的离线层之间增加了NearLine（近线）层，以实现计算规模和时效性的折中。
“训练”推荐系统就请你不吝表达和互动，用你的反馈支持服务提供商和内容创作者。对于令你满意的服务和产品，登录是最好的肯定，在登录后，你的所有行为轨迹就不会丢失，在更换设备之后仍然能够获得稳定的服务体验；对于令你满意的内容，请果断地点赞、评论；对于你喜欢的作者，可以关注他的后续动态。“赠人玫瑰、手有余香”，这些典型正向反馈能够让算法更快速地收敛并确定你的喜好。对于令你厌恶的内容，也请点个“×”，明确屏蔽掉特定关键字，让系统不再做无用的探索。
完善用户画像既可以通过尽可能多的外部渠道数据塑造用户来实现，也可以借助产品设计和运营活动引导用户多沉淀行为来实现。
规则是在排序环节之后生效的
短期的干预是应该逐步被长期的机制所替换的。
◆ 推荐的起点：断物识人 在我们设计系统时，可以先基于产品场景快速覆盖主要标签，再结合标签集合的使用频次、专家建议等因素逐步将部分入口收敛到树状的分类体系中来。
简短评论：最高门槛的评判，深度用户沉淀内容
在这种情况下，我们需要引入聚类的方式来描述。这种方式并不是以标签词的方式来定义事物是怎样的，而是基于某一维度的特征将相关物品组成一个集合，并告诉你这个新的物品同哪个集合相似。 clustering the similar items depending on the feature of some dimensions, and classify the new item to the most similar cluster
通常，用户画像有三类主要应用场景：
（1）精准广告营销。用户画像对广告营销来说是最典型的应用场景。当给用户打上各种维度的标签之后，广告主就能够借助这些标签来圈定用户，以便更有效率地触达目标人群。我们以脸谱网的广告投放系统为例，广告主可以选择地域范围、年龄范围、性别、兴趣标签等。通过选择这一系列标签，系统也会实时反馈给广告主目前框定的候选人数。
（2）行业研究。借助用户画像，我们可以了解不同行业的动态进展。比如，90后、00后的购物娱乐消费分析，不同地域用户的消费差异分析，特定行业中用户的消费特点，等等。通常，平台会定期发布此类报告，帮助内外部人士更好地了解细分领域的最新特点。比如，在腾讯大数据（http://bigdata.qq.com/reports）上，你就可以查看到过往发布的行业研究报告。
（3）产品效率优化。信息匹配是最典型的场景，无论是国内的今日头条、淘宝，还是国外的YouTube、脸谱网，其平台都是基于用户的画像信息来优化推荐排序，以实现人和信息的高效匹配，从而提升效益、降低成本的。据Netflix估算，个性化推荐系统每年为它的业务节省的费用高达10亿美元。坊间传闻，基于用户画像的推荐排序还有一些灰色的应用：比如真假货混发，罗振宇在跨年演讲“时间的朋友”中提到，某不良商家会根据用户的收货地址来预估用户的认知水平，从而决定是发送真货、高仿还是假货；又比如价格歧视，同样一件商品添加进购物车后，不同的用户可能会收到不同的后续反馈，价格敏感型的用户更容易收到优惠券。
我们通常将用户画像数据划分为静态和动态两类。静态用户画像数据：用户独立于产品场景之外的属性，如性别、学历、年龄、婚育状况、常驻位置等。这些信息往往相对稳定，可通过第三方联合登录、用户表单填写等方式获取。静态数据通常具有统计性意义，比如常驻位置在某高档小区的用户可能付费能力更强，女性用户可能冲动性消费更多等。动态用户画像数据：用户在产品场景中所产生的显式或隐式行为。显式行为包括对某篇内容点赞、评论、分享，关注了某个作者等。在众多显式行为中，由于产品场景的不同，不同行为的权重也不相同（如对于电商场景，购买的权重&amp;gt;购物车的权重&amp;gt;查看的权重）。隐式行为包括在某页面的停留时长、用户的操作行为轨迹等。通常，显式行为的权重要高于隐式行为，但是由于显式行为更稀疏，所以需要隐式行为来补充验证。
以下是一些常见的静态或动态用户画像数据： 位置信息。不同产品对常驻位置有不同的应用方式：推荐本地新闻和特定水电暖通知之类的内容是能够想到的最直观的应用场景；美食团购类应用，是默认基于身边位置进行推荐的。但是，当你离开常驻城市进入其他城市时就会发现，应用中会增加一个旅行者模块，其提供的内容更多考虑知名度而非距离因素。[插图]图2-8 美食团购类应用基于位置推荐示例除了常驻城市的应用外，对于朝九晚五的上班族来说，还有常驻地点的概念，如高德地图和滴滴打车中提供的“家”和“公司”的选项。基于日常轨迹和常驻地点，系统可以进行一些远距离的推荐，如可以在下班时段推荐家附近的饮食或尝试推荐沿途的消费地点。
搜索信息。搜索是一个显著表明短期意图的行为，具有随时间衰减的特性。以淘宝为例，当你搜索“螃蟹”之后，那么无论是在淘宝的首页横幅广告，还是在接入了淘宝广告的应用，你都能看到关于“螃蟹”的广告。而当搜索行为过去一段时间或是在你显式购买之后，这类广告的展现就应该降低或停止。
评分。评分是最常见的量化行为。如淘宝、京东等购物网站对购物行为不同维度的点评，豆瓣对书籍和电影的打分等，一般都设置为1～5分的评分机制。需要注意的是，不同用户有不同的打分偏好，比如有人习惯性好评，有人则偏严格。因此，需要将用户的历史平均分作为基准进行归一化处理，以衡量用户评分行为背后的认可度。
收藏。收藏表达了用户对内容的偏好程度。在内容领域，具有工具性或实用性的内容通常更容易被收藏。在电商领域，收藏和加入购物车一样都是用户购买意图的体现。
分享。除了表达喜好外，分享还传递了用户的立场和态度。比如，用户会阅读、评论很多热门的内容，但在转发的操作上是审慎的。转发到微博或微信朋友圈的动作代表了用户在用自己的社会身份扩散内容。从某种角度而言，转发的肯定意义比收藏、评论等行为的意义要大。
评论。评论代表了参与度，但不一定明确地关联到态度的好恶。对评论的处理需要进一步进行文本分析，以获取用户的表意性和情感倾向性。在产品层上，淘宝的宝贝印象算是一个典型应用，通过抽离出用户的共同评语来辅助新的消费者进行决策。
播放比例或播放时长。与点击行为相比，播放时长是一个相对隐性的行为。我们通常可以用播放时长来衡量用户对特定视频点击后的消费体验。2012年，YouTube就已经调整视频排序算法，将获得观看时长更多的视频排在更优先的位置。
◆ 推荐算法：物以类聚，人以群分 推荐算法：物以类聚，人以群分
以内容推荐为例，其用于相似度计算的常见因素有：作者层面的相似性（基于订阅或偏好关系），内容层面的相似性（如关键词、话题、类目、聚类、标签等）。
基于内容属性推荐的好处在于，只依赖物品本身的特征而不依赖用户的行为，让新的物品、冷僻的物品都能得到展示的机会。其存在的问题在于，推荐质量的优劣完全依赖于特征构建的完备性，但特征构建本身是一项系统的工程，存在一定成本。在上面的例子中，如果标签词粒度不够细，不能够全面描述书的内容（比如每本书的标签词只有三个），就很难计算出置信的相似度，达不到足够好的推荐效果。
人以群分：基于用户行为的协同过滤
把用户的消费行为作为特征，以此进行用户相似性或物品相似性的计算，进行信息匹配，是协同过滤（Collaborative Filtering）的基础。
协同推荐可以分为三个子类：基于物品（Item-based）的协同、基于用户（User-based）的协同和基于模型（Model-based）的协同。
基于用户的协同就契合了上面的例子，其基础思路分为两步：第一步，找到那些与你在某一方面口味相似的人群（比如你们都是新手爸妈，倾向于同一种教育理念）；第二步，将这一人群喜欢的新东西推荐给你。
基于物品的协同，其推荐的基础思路是：先确定你喜欢什么物品，再找到与之相似的物品推荐给你。只是物品与物品间的相似度不是从内容属性的角度衡量的，而是从用户反馈的角度衡量的。
大家一度认为基于物品的协同要优于基于用户的协同，这是因为大型电商网站的用户数量往往远大于商品数量，且商品的更新频率相对较低，基于物品的协同能够以离线运算的方式获得更好的推荐效果。但对新闻推荐系统、社交性推荐系统等而言，其物品是海量和频繁更新的，故而基于用户的协同也有着相应的用武之地。
基于模型的协同，是用用户的喜好信息来训练算法模型，实时预测用户可能的点击率
比如，在Netflix的系统中就将受限玻尔兹曼机（Restricted Boltzmann Machines, RBM）神经网络应用于协同过滤。将深度学习应用于基于模型的协同，也成了业界广泛使用的方式。</description>
    </item>
    
    <item>
      <title>读书笔记：《痛点：挖掘小数据满足用户需求》</title>
      <link>https://ffflora.github.io/cn/small-data/</link>
      <pubDate>Sat, 16 Nov 2019 22:46:13 -0800</pubDate>
      
      <guid>https://ffflora.github.io/cn/small-data/</guid>
      <description>◆ | 第一章 | 被刺激的欲望   他发现洛杉矶市的每个人都匆匆忙忙地买圣诞礼物，送给他们大多不了解的人
  弗雷泽写道，世界人民把西伯利亚当作一个比喻。它暗示着被拒绝、被漠视的地理条件或社会条件。西伯利亚是饭店厨房门口的桌子，是家里看不到电视比赛的座位，是一场没人出现的聚会。从地理概念上讲，西伯利亚是指从北冰洋到哈萨克斯坦山区，再到蒙古和中国边境大约800平方英里的大陆块。
宗教警察，即美德促进与犯罪防御委员会，是由一群男性组成的。他们在城市、小镇、餐馆、咖啡厅、商店和商场里巡逻，报告和纠正所有败坏道德的行为。他们负责落实着装规范，并确保在中午、下午、傍晚和夜间祈祷期间，所有商店都关闭半个小时。
他们的举止中也充满克制和谨慎。他们似乎不爱玩捉迷藏类的游戏，反而以保护和照顾类为主。我从书架上拿下的童书，大多数也是相似的主题。这表明，我从沙特母亲身上发现的恐惧，都传递给了孩子。浏览一个国家的童书，通常是很有启发的，因为童书帮我们建立了最初的期待。
沙特孩子喜欢的玩具，却是对天真的挑战。他们将近4/5的玩具是消防车、救护车或警务车。
◆ | 第二章 | 香肠、烤鸡和对真正幸福的追逐 每7分钟，人类的味觉就会“重置”一次。
与美国的友好形成鲜明对比的是缺乏身体接触。在美国，没人会触碰别人的身体。如果有人不小心碰到了别人，大多数人都会立即道歉。
最惊人之处在于，美国主流的幽默感关注的主题，大多不是茶余饭后的谈资。无论参观任何一个喜剧俱乐部，还是观看《最爆伴娘团》《抑制热情》《辛普森一家》《南方公园》《恶搞之家》或者YouTube上的路易斯·C. K. 脱口秀，你都会发现，美国人愿意掏几百万美元，就是为了听到大多数人感受到、想得到，却从不在公开场合谈论的话题
政治正确性基本上源于两个因素：恐惧和族群。
1994年，在《笛卡儿的错误：情绪、推理和人脑》一书中，作家与神经学家安东尼奥·达马西奥提出了躯体标记假设。在书中，达马西奥描述了一种假设机制——我们的决策情绪反应出现调整和偏差，主要是因为受大脑控制。如果你把手放在烤炉上被烫了，大脑会记录那个瞬间。但是，从那以后，我们会做的，不是每晚把手放在同一台烤炉上，期待出现不同的结果。我们会对烤炉格外小心。这种行为的发生，是因为大脑中有躯体标记，可以永久标记我们的经历。它会把两件事画上等号：热炉=疼痛。一些躯体标记是有意识的，另一些是无意识的，但大多数源于长期的经验。例如，我告诉观众，2001年9月11日的世贸中心遇袭，就构成了一个躯体标记。灾难发生时，我们都记得自己在哪儿，跟谁在一起。但是，我们记得去年生日吃了什么吗？这就是躯体标记和特定记忆间的区别。
我所说的自由是不用担心，不用刻意，没有负担，是一种做回孩子的自由自在。
◆ | 第三章 | 印度的统一色 “在德里，广阔提哈监狱关了1.2万名服刑人员。其中，一部分女犯人被关在类似营帐的专门牢房里，被称为‘婆婆房’。”她们大部分都是“一时气愤”暴打儿媳的婆婆们。
说起来你可能都不信，不过，我们对颜色的偏好通常源于小时候卧室墙的颜色。
印度政府还认为，如果产品包装印上新生儿的形象，制造商可能误导消费者，让他们以为，他们的孩子有一天会像包装上的小模特一样漂亮。
◆ | 第四章 | 在快餐、中东影院和酒店泳池的帮助下直击减肥 友谊可能算一种归属，但它却以另外一种方式在起作用。朋友群会影响我们的外貌。《新英格兰医学期刊》上一项将近10年的研究发现：“肥胖会像病毒一样，由一个人传染给另一个人……当一个人体重增加时，最亲密的朋友也会跟着变胖。”这项新研究的主要研究者、哈佛大学教授尼古拉斯·克里斯塔奇斯解释道：“其中一个原因，就是朋友会互相影响对肥胖的认知。好朋友变肥后，肥胖看起来就没那么糟糕了。”简单说来，根据《纽约时报》上的有关报道，根据周围人的表现，我们可接受的体型也会发生改变。
2013年，墨西哥总统恩里克·培尼亚·涅托开始引入全国苏打税，限制消费者沉醉于没营养、高热量的食品。
而且，按照传统，沙特女性是不可以锻炼身体的。而沙特男性却“获准”出现在公开场合，甚至可以慢跑。2015年起，沙特女性可以在学校锻炼身体，参加体育项目，但这一变化也不乏争议。根据美国全国公共电台的报道，一些宗教保守人士认为，女孩参与训练“是受到西方化思想的影响……会导致通奸和卖淫”。
在营销界，“切入点”（entry point）是指身份认知受到挑战，或身份转变的时刻——包括结婚、怀孕、买房子、第一次当父母、儿女长大离家。在这期间，顾客们尤其容易受到新观点和新品牌的影响。
第一个叫“蓝色剧本”，完全是功能性的。里面全是屏幕上要呈现的要素，包括对话、道具、摄影视角和场景描述。第二个剧本，希区柯克称为“绿色剧本”，里面描述了电影的内容细节、情感主线或“故事节奏”。
◆ | 第五章 | 被赛马、衬衫领、宗教信仰拯救的巴西啤酒品牌 巴西的民族认同感围绕三样东西：足球、啤酒和海滩。
苹果的“粉丝”是世界上最热情的品牌推销员。
社区能给人带来亲切感和归属感，但是，“线上的社区”越多，真实的社区就会越少。
只要顾客用的是同一种语言仪式，同一种做事方式，他们就能联系在一起。仪式是顾客加入一个特殊群体的通行证。他们重复某个仪式的次数越多，就越有可能成为死忠粉
如果我们能用多重感官“记录”一种经历，往往会比单一感官的记忆深刻200%。如果增加社交因素或归属感，我们对这段经历的记忆就会更深刻。
一般说来，仪式是一种可以改变我们情绪、社交和身体状态的特定行为模式或语言模式。大多数仪式分为两个层面。第一层面注重具象和感觉，第二层面注重抽象和情绪。
每个酒吧里都有一支笔、一个笔记本和一个黑盒子。顾客们先把工作问题记下来，放进盒子里，再跟朋友大喝一场。转换。顾客们想逃避里约的人群、肮脏、灰尘、贫穷和无尽的宗教礼拜。
我们通常记住的，不是一种饮料、一种口味，而是喝饮料时发生的故事。有关品牌的谈话越能鼓舞人心，我们越觉得自己是这个群体的一部分。
◆ | 第六章 | 不见的护手霜
对大多数零售商来说，过程是这样的：收到裁剪、颜色和尺寸等详细要求后，中国大陆的工厂工人就开始制造衣服。然后，制成的衣服登上集装箱船，开始了长途的跨洋之旅。只要衣服一到目的地，工人们就把衣服搬上卡车，送到销售渠道和区域店面。最差的情况是，集装箱船在运输途中，某种时装或款式意想不到地变换了趋势——蓝色风盖过了黑色风，买家不知道为什么开始讨厌绿色。相反，一些零售商甚至会让船返航，毁掉船上的货物。据说，总部位于西班牙的飒拉（Zara）和其他零售商已经开始在海外货船上生产服装。那些货船上配备大型生产线，可以在最后一刻应对时尚趋势的巨大转变。
着装认知是一个科学研究领域的变体。这个领域叫具身认知（embodied cognition），认为“人类不只用大脑思考，还用身体思考”[插图]。反过来，我们的身体会“在大脑里产生不同的抽象概念，再影响我们的行为”[插图]。
事实上，从早上一睁开眼开始，我们大多数人不知不觉都在寻找一些外部标志，渴望带来转变。我们的智能手机，我们的第一杯咖啡，我们冲个澡、洗个头、刮腿毛、刮胡子、换上工作服，都是转变的仪式。一天结束时，我们卸了妆，换了衣服，又回到原来的样子
以前，几乎所有孩子的卧室主角都是桌子、椅子、台式电脑或手提电脑。今天，这个主角变成了床。在过去的几年里，青少年把床看成“指挥所”，床的概念也因此得到了扩展。没错，一些孩子还趴在桌上写作业。不过，对大多数青少年，甚至是大学生来说，他们可以在床上读书、学习、打瞌睡、发短信、发邮件、听音乐、看视频、弯腰坐下、脸书视频通话、Skype网络电话聊天。而且，这些通常是同时进行的。</description>
    </item>
    
    <item>
      <title>Notes on the paper (NLP): Character-level ConvNets for Text Classification</title>
      <link>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</link>
      <pubDate>Tue, 05 Nov 2019 22:14:01 -0800</pubDate>
      
      <guid>https://ffflora.github.io/posts/character-level-convnet-for-text-classification/</guid>
      <description>Background Knowledge  CNN One-hot encoding  Some highlights of the paper When trained on large-scale datasets, deep ConvNets do not require the knowledge of words, in addition to the conclusion from previous research that ConvNets do not require the knowledge about the syntactic or semantic structure of a language. (Chinese News corpus convert to pinyin first, and then apply this model achieves only 10 something testing error.)
Dataset size forms a dichotomy between traditional and ConvNets models: the larger datasets tend to perform better.</description>
    </item>
    
    <item>
      <title>Notes on the Paper (NLP): Skip-thought Vectors</title>
      <link>https://ffflora.github.io/posts/skip-thoughts-paper/</link>
      <pubDate>Sun, 27 Oct 2019 01:21:49 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/skip-thoughts-paper/</guid>
      <description>Paper
Code
Background Knowledge Sentence representation
Bag of words representation
Sen2Vec/Doc2Vec
Some highlights of the paper Instead of using a word to predict its surrounding context, this model encode a sentence to predict the sentences around it. The model depends on having a training corpus of contiguous text.
The model treat skip-thoughts in the framework of encoder-decoder models. That is, an encoder maps words to a sentence vector and a decoder is used to generate the surrounding sentences.</description>
    </item>
    
    <item>
      <title>Set Up Network and HTTP Load Balancers in GCP</title>
      <link>https://ffflora.github.io/posts/network-and-http/</link>
      <pubDate>Sat, 14 Sep 2019 22:30:48 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/network-and-http/</guid>
      <description>This note is based on GCP Qwiklab Essentials.
Create multiple web server instances To simulate serving from a cluster of machines, create a simple cluster of Nginx web servers to serve static content using Instance Templates and Managed Instance Groups. Instance Templates define the look of every virtual machine in the cluster (disk, CPUs, memory, etc). Managed Instance Groups instantiate a number of virtual machine instances using the Instance Template.</description>
    </item>
    
    <item>
      <title>How to Setup Kubernetes in GCP</title>
      <link>https://ffflora.github.io/posts/kubernetes/</link>
      <pubDate>Sat, 14 Sep 2019 21:02:06 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/kubernetes/</guid>
      <description>Creating a Kubernetes Engine cluster gcloud container clusters create [CLUSTER-NAME] Get authentication credentials for the cluster gcloud container clusters get-credentials [CLUSTER-NAME] Deploying an application to the cluster use kubectl run command to create a new Deployment
kubectl run hello-server --image=gcr.io/google-samples/hello-app:1.0 --port 8080 This Kubernetes command creates a Deployment object that represents hello-app. In this command:
 --image specifies a container image to deploy. In this case, the command pulls the example image from a Google Container Registry bucket.</description>
    </item>
    
    <item>
      <title>正则表达式中的 re.S 在 Python 中的使用</title>
      <link>https://ffflora.github.io/cn/re.s-in-python/</link>
      <pubDate>Tue, 10 Sep 2019 00:56:58 -0700</pubDate>
      
      <guid>https://ffflora.github.io/cn/re.s-in-python/</guid>
      <description>今天在使用 Python Regex 的时候遇到了一个神奇参数 re.S, 这玩意儿的学名是 dot matches all,
 Make the &#39;.&#39; special character match any character at all, including a newline; without this flag, &#39;.&#39; will match anything except a newline.
 在使用这个参数时，可以使 Regex 的操作作用在全部字符串中，包括 \n 和缩进。在没有使用此参数时， Regex 的操作会忽略 \n.
Example:
import re test1 = &amp;#39;abcabc123flora789 github jiang996&amp;#39; test2 = &amp;#39;&amp;#39;&amp;#39;abcabc123flora 789 github jiang996&amp;#39;&amp;#39;&amp;#39; a = re.findall(&amp;#39;flora(.*?)jiang&amp;#39;,test1) b = re.findall(&amp;#39;flora(.*?)jiang&amp;#39;,test1,re.S) c = re.findall(&amp;#39;flora(.*?)jiang&amp;#39;,test2) d = re.findall(&amp;#39;flora(.*?)jiang&amp;#39;,test2,re.S) print(a,&amp;#39;\n&amp;#39;,b,&amp;#39;\n&amp;#39;,c,&amp;#39;\n&amp;#39;,d,&amp;#39;\n&amp;#39;) output:</description>
    </item>
    
    <item>
      <title>Resnet 算法详解</title>
      <link>https://ffflora.github.io/cn/resnet/</link>
      <pubDate>Fri, 06 Sep 2019 18:08:34 -0700</pubDate>
      
      <guid>https://ffflora.github.io/cn/resnet/</guid>
      <description>ResNet 详解 The Resnet Paper is here: Deep Residual Learning for Image Recognition
Netscope CNN Analyzer
网络加深性能并不一定使模型变得更强，层数更多并不总是有更准确的结果，解决方法之一是 可以构造一个性能与浅层模型相当的结构。Residual function 顾名思义就是残差，是根据论文里 Figure2, y = F(x) + x, 需要学习的是 F, F(x) = y - x, F 就是 residual.
残差学习？残差网络？ 残差学习模块有两个分支：一是左侧的残差函数，二是右侧的对输入的恒等映射。这两个分支经过对应元素的相加之后，再经过一个非线性的变换 ReLU 激活函数，从而形成整个残差学习模块。将若干个残差模块堆叠，就成为了 残差网络。
ResNet 可以构建很深的神经网络，比如 ResNet -50/101/152 等。
ResNet - v2 ResNet 后期推出了更多其它的链接方式，但是实验之后发现还是没有 identity shortcut 好。
Pre-activation Residual Module:  原先 Residual Block 是 CBR(Conv, BN, ReLU) 结构 BRC(BN, ReLU, Conv) 结构 activate 在 conv 之前。被称作为 pre-activation 结构。  ResNeXt ResNeXt 转向对神经网络拓扑设计的研究，对 block 堆叠的策略；</description>
    </item>
    
    <item>
      <title>读书笔记：《九败一胜》</title>
      <link>https://ffflora.github.io/cn/wang-xing/</link>
      <pubDate>Fri, 06 Sep 2019 15:07:48 -0700</pubDate>
      
      <guid>https://ffflora.github.io/cn/wang-xing/</guid>
      <description>九败一胜：美团创始人王兴创业十年 第2章 在创业的黄金时代里 过去的长期经验不是最重要的，快速学习能力是决定一个人发展现状以及未来前景的重要因素。 尊重契约精神，尊重大家共同定好的游戏规则，没有这个，创业就无从谈起。
以身作则不是塑造公司价值观的最好办法，而是唯一办法。
第3章 创业是更充实的生活方式 大家就知道了，一个创业团队里必须有大股东，必须有能拍板的人
第4章 自省吾身：抱怨不是创造性的力量 我问王兴，饭否办公室的空座怎么办？他回答，将来会坐满的。“我很幸运，生在中国，生在这个时代。如果早生30年，我能参与的事情完全不一样。如果不是生在中国，而是利比亚、刚果，那就不一样了。我很庆幸生在这个时代，这是我内心的想法，不是装的。没有什么不值得乐观的，这很简单：有事做，有希望，有人爱。”
第5章 领先一步：王兴为何总是第一个 异类的一万个小时是全情拥抱、全心投入、全力奔赴的一万个小时，而不是很多上班的人周而复始、机械麻木的八小时累积起来的一万个小时。
他不是天生智商就高人一等的，而是好学高人一等。就像挖坑一样，天才一铲子挖一尺，你一铲子挖一寸，坚持挖十天，别人来看坑的时候，也觉得你聪明，居然能挖出这么深的坑。王兴所表现出来的聪明是长期学习之后形成的结果。
总结起来，王兴本人有三个特点：
 对世界充满好奇，始终保持开放的心态学习。
 独立思考，就算做士兵，也要做明白为什么要打仗的士兵。
 长期专注于研究互联网领域  他比较坚持，又不会很固执，只要有足够的理由就能说服他。同时他是苛刻的，追求完美的，他不会骂人，不过要得到他的赞许很难。他始终给人一种压力：你必须跟顶级的东西看齐。
“我想活在一个更好的世界里，每个人都是这样想的。但我们注定在这个世界里，不可能在别的世界里，所以我们做好事情，改变世界，对我们自己是有好处的。” //所以改变世界的梦想不是中二，是人人都可以有的坚持。
第6章 美团的发轫：互联网逻辑学 就像王兴评论微信：“无数人看到了这个机会，腾讯看到了，雷军看到了，我也看到了。光看到这个机会是没有用的，回头来看，也没什么创业公司能够出头儿，因为腾讯看得足够早，足够强，足够坚决。”
赌博是浓缩在一个时间点里干这件事，你可以把生活看作终极的游戏，生活是更大的赌场，这样你就不需要玩儿这些了。
以网游角色举例，王兴将玩家分为四类：一是探索者，尽量尝试新东西，使自己的地图大些；二是成就者或积累者，不厌其烦去打仗，去挖金子，只是为了等级更高；三是毁灭者，目的是把别人干掉，游戏的快感来自毁灭别人；四是社交者，目的是在里面结识一些真人，他们进行谈话，可能跟游戏主题无关。 我问他属于哪种类型。他回答：“相对适合我干的是架构师。” 这是一个出乎意料的答案。不是吗？他自己给出了角色的限定范围，我的思路顺着他给出的限定范围走，偏偏他自己跳出限定范围来定义自己。这就是王兴的思维方式。
想要做大事的人，最忌讳的就是躺在过去的事情上。
远见不是凭空而来，必须有获取信息并整理分析的能力。
创业有时候比拼的是谁犯的错误更少，用更少的钱活得更久。
在其他团购网站打广告的同时，美团网在开发系统，各种IT管理系统、财务系统，招各种技术人才，以及高管，建设团队。王兴把精力花在这些上，决定了后续美团网为什么比别人走得更稳，花钱更少，效率更高。
所以过去一年虽然取得了很多激动人心的发展，但还只是在一个伟大事业的最最初期的开端。
创业人分为天派和地派，之前我一直被认为属于天派，最近很多人认为我是在向地派转。其实，我一向喜欢跳出问题回答问题，我觉得并不是只有天派和地派，可能还有一个人派。老祖宗说天时不如地利，地利不如人和。我觉得在这个事情里面，时机很重要，这些资源很重要，但是更重要的是这个团队。
第7章 美团的背面：线上很强，线下也强 他以前创过业，知道不管企业蓝图有多么美好，目标有多远大，也得把每天的事情做好，等着机会来到。
在微博上，王兴解释过他如何认识竞争：“同向为竞，相向为争。”
王慧文还有一层意思是，当时浮夸风气很盛，融资100万美元说有500万美元，我们不想参与浮夸，亮一下账户划清界限。在新闻发布会上，王兴干了一件前所未有的事，面对众多记者，公示账户上躺着6200万美元。现场照片一时在互联网上疯狂传播。
拉手网和窝窝团的失败，不是因为美团网做得有多好，而是他们没有把核心力量放在经营客户上，期望通过资本力量先圈地，再深耕。但是，一般这么想的，到最后也不会回过头来深耕。他们并未将团购的本质想得足够清楚，只是追逐热点，期望做一家上市公司。
干嘉伟说：“我不相信一个人赶上好时代就能把事情做起来，我相信事情是一步步干出来的。
我和王兴谈到人工智能（AI）的时候，王兴提到“智能增强”（IA），他认同鼠标发明者恩格尔巴特的理念，别让计算机去干最核心的智能的事情，先把周边的事情全扫掉，让人做智能判断。谷歌引进的也是IA，乔布斯最早解释苹果也是说，我们不是代替mind。
干嘉伟说：“你不在那个世界里，很难理解那个世界的事。逐级布置任务，但要跨级了解情况，只有直接到一线才能了解你所有的管理要求有没有落地。”
王兴会觉得销售团队执行力怎么会是这么大的问题，在技术人员那里，敲一下Enter键就可以按照上级要求解决问题。但在销售团队，你提了要求他当面说好，背后可能是另一回事。而且人的行为模式也不是那么容易调整的，需要管理手段。
干嘉伟敢于跟王兴吵架也有王兴本人的因素：第一，王兴是极度理性的；第二，王兴的道德水准干嘉伟信得过。
这是因为这个世界上竞争从来都非常激烈，当有一个大的机会的时候，没有可能只有你看到了，基本是差不多时候有一帮人也看到了，这跟其他无数的场合竞争都很像，一个真正有吸引力的机会，会在差不多同一时间有不止一个团队、不止一个公司或者不止一个人参与，一定会有激烈的竞争。
所以，差不多时间出发，早一点到和晚一点到，完成目标和没完成目标的区别，就是胜利跟失败的区别。
所以，这里成功跟失败的区别不光是你是否获得荣誉，是否完成目标，而已经是生与死的差别。
就是不管天气好坏，阿蒙森团队坚持每天前进大概30公里，这句话听起来非常简单，但是事后总结，这个是阿蒙森团队能够不断成功而且生还的一个非常重要的原则。他们做了充分的准备，天气好的时候，似乎每天走30公里很容易。天气这么好，路是下坡又很顺，我们走得快一点儿吧；现在我们吃得饱、精力很旺盛，我们快一点儿吧。但是阿蒙森没有这么干，他坚守他的计划，每天不紧不慢地前进30公里。在一个极限环境下面，你要做到最好，但是你要做到可持续的最好，你就不能太努力，一旦你出汗就非常非常糟糕。如果你太用力，一兴奋，出汗了，那么待会儿风一吹就结成冰了。所以任何时候，太激进其实很有可能会带来长期的负面影响。做到这点需要高度严守既定的纪律，在事情容易的时候，在环境顺利的时候，不要得意忘形，坚守纪律，当情况好的时候，似乎容易的时候，前进30公里，然后扎营、休息。当天气不好的时候，阿蒙森也坚持带领他的团队，哪怕挪得很慢，也要前进30公里，完成这一天的目标。因为本身设的目标是有富余量的，天气不好就慢一点儿，路陡就慢一点儿，但坚持去完成。
一个简单的事情重复做，越做越好，越做越专业，不管是在哪个岗位上，这个事情听起来似乎很枯燥，但是它其实蕴含着无数的激情，这是真正的激情，并不是莫名其妙的不同的变化，而是你做成的事情，你要希望把它做到最好，做到越来越好，要做到比最好还更好，每天越来越好。这是一个很难的事情，但是是一个很激动人心的事情，也是非常值得努力的事情。
第8章 美团的灵魂：是什么让王兴难以复制 做公司就像造房子一样，愿景是房顶，使命是地板，价值观是墙壁。
我觉得价值观最厉害的地方就在于，你在面对巨大诱惑的关键时刻要坚守住，别人才会在关键时刻信任你。《素书》上说，上无常操，下多疑心。所谓常操是什么？就是你长期遵循的价值观和规则。
小公司做起来关键是抓住了一个机会；中等公司的关键是有一批比较强的高管，大公司的关键是要有正确的流程和价值观。
你对未来越有信心，你对现在越有耐心。
第9章 美团的未来：O2O帝国？ 企业家精神最精到的描写是，企业家本质是对机会的追求，暂时无视自己现在控制多少资源。
第10章 十年之思 “大部分人望着高峰，但他一生从来不曾攀上过，只是听听别人的经验就已经很满足，而自己不愿意花费任何心血；第二种人依照前人的成功经验，成功登顶了；第三种人没有登顶的经验，但是他又怀疑前人登顶的经验，于是他决定自己探索出一条路来，最终也成功登顶了。第三种人于是明白了，登山没有一条唯一固定的道路，有多少人就有多少条路。”
我学到，人非常重要的状态是既非常自信又非常谦逊。</description>
    </item>
    
    <item>
      <title>How to be a Kaggle Master?</title>
      <link>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</link>
      <pubDate>Thu, 05 Sep 2019 13:27:11 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/how-to-be-a-kaggle-master/</guid>
      <description>How to be a Kaggle Master Kaggle Combo x3:
Feature Engineering, Model Tuning, Model Ensemble Data Preprocessing: Missing values imputation:  Numeric Features  Impute with mean for normal distributed feature Impute with median for skewed distribution (reduce the impacts of outliers)  Categorical Features  Majority Imputation  Supervised Learning Imputation  Regression/Classification  XGBoost/LightGBM:  Missing values are gracefully treated by considering missing values as candidate for tree splitting point.</description>
    </item>
    
    <item>
      <title>Use Auto-completion in gcloud</title>
      <link>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</link>
      <pubDate>Wed, 28 Aug 2019 00:02:53 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/gcloud-and-cloud-shell/</guid>
      <description>This notes is from Qwiklabs GCP Essentials.
Auto-completion gcloud interactive has auto prompting for commands and flags, and displays inline help snippets in the lower section as the command is typed.
Static information, like command and sub-command names, and flag names and enumerated flag values, are auto-completed using dropdown menus.
Install the beta components:
gcloud components install beta Enter the gcloud interactive mode:
gcloud beta interactive When using the interactive mode, click on the Tab key to complete file path and resource arguments.</description>
    </item>
    
    <item>
      <title>How to read csv files under .gz in Kaggle kernel?</title>
      <link>https://ffflora.github.io/posts/read-gz-in-kaggle/</link>
      <pubDate>Tue, 27 Aug 2019 00:23:55 -0700</pubDate>
      
      <guid>https://ffflora.github.io/posts/read-gz-in-kaggle/</guid>
      <description>It took me long time to figure it out.
Say if the files&amp;rsquo; directory in the Kaggle kernel looks like this:
competitive-data-science-predict-future-sales sales_train.csv.gz sales_train.csv When I try to list all the files in the directory, I realize that there&amp;rsquo;s no need to unzip the .gz file in order to get the .csv files, since
import os data_dir = &amp;#39;/kaggle/input/competitive-data-science-predict-future-sales&amp;#39; os.listdir(data_dir) the output is:
[&amp;#39;test.csv&amp;#39;, &amp;#39;item_categories.csv&amp;#39;, &amp;#39;sales_train.csv&amp;#39;, &amp;#39;sample_submission.csv&amp;#39;, &amp;#39;items.csv&amp;#39;, &amp;#39;shops.csv&amp;#39;] Thus in order to use the .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ffflora.github.io/render/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ffflora.github.io/render/</guid>
      <description>Awesome-pyechartsvar chart_f004fbb53bef41948d6148e8f915d66b = echarts.init(document.getElementById(&#39;f004fbb53bef41948d6148e8f915d66b&#39;), &#39;white&#39;, {renderer: &#39;canvas&#39;});var option_f004fbb53bef41948d6148e8f915d66b = {&#34;animation&#34;: true,&#34;animationThreshold&#34;: 2000,&#34;animationDuration&#34;: 1000,&#34;animationEasing&#34;: &#34;cubicOut&#34;,&#34;animationDelay&#34;: 0,&#34;animationDurationUpdate&#34;: 300,&#34;animationEasingUpdate&#34;: &#34;cubicOut&#34;,&#34;animationDelayUpdate&#34;: 0,&#34;color&#34;: [&#34;white&#34;,&#34;#c23531&#34;,&#34;#2f4554&#34;,&#34;#61a0a8&#34;,&#34;#d48265&#34;,&#34;#749f83&#34;,&#34;#ca8622&#34;,&#34;#bda29a&#34;,&#34;#6e7074&#34;,&#34;#546570&#34;,&#34;#c4ccd3&#34;,&#34;#f05b72&#34;,&#34;#ef5b9c&#34;,&#34;#f47920&#34;,&#34;#905a3d&#34;,&#34;#fab27b&#34;,&#34;#2a5caa&#34;,&#34;#444693&#34;,&#34;#726930&#34;,&#34;#b2d235&#34;,&#34;#6d8346&#34;,&#34;#ac6767&#34;,&#34;#1d953f&#34;,&#34;#6950a1&#34;,&#34;#918597&#34;],&#34;series&#34;: [{&#34;type&#34;: &#34;effectScatter&#34;,&#34;</description>
    </item>
    
  </channel>
</rss>